{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52d7201c",
   "metadata": {},
   "source": [
    "Q1: NLP Preprocessing Pipeline\n",
    "Write a Python function that performs basic NLP preprocessing on a sentence. The function should do the following steps:\n",
    "\n",
    "1. Tokenize the sentence into individual words.\n",
    "2. Remove common English stopwords (e.g., \"the\", \"in\", \"are\").\n",
    "3. Apply stemming to reduce each word to its root form.\n",
    "   Use the sentence:\n",
    "   \"NLP techniques are used in virtual assistants like Alexa and Siri.\"\n",
    "   The function should print:\n",
    "   • A list of all tokens\n",
    "   • The list after stop words are removed\n",
    "   • The final list after stemming\n",
    "   Expected Output:\n",
    "   Your program should print three outputs in order:\n",
    "4. Original Tokens – All words and punctuation split from the sentence\n",
    "5. Tokens Without Stopwords – Only meaningful words remain\n",
    "6. Stemmed Words – Each word is reduced to its base/root form\n",
    "\n",
    "Short Answer Questions:\n",
    "\n",
    "1. What is the difference between stemming and lemmatization? Provide examples with the word “running.”\n",
    "2. Why might removing stop words be useful in some NLP tasks, and when might it actually be harmful?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "690b0149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['NLP', 'techniques', 'are', 'used', 'in', 'virtual', 'assistants', 'like', 'Alexa', 'and', 'Siri', '.']\n",
      "tokens without stop words: ['NLP', 'techniques', 'used', 'virtual', 'assistants', 'like', 'Alexa', 'Siri', '.']\n",
      "words after stemming: ['nlp', 'techniqu', 'use', 'virtual', 'assist', 'like', 'alexa', 'siri', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gadda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gadda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    print(f\"tokens: {tokens}\")\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    print(f'tokens without stop words: {filtered_tokens}')\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "    print(f'words after stemming: {stemmed_tokens}')\n",
    "    \n",
    "sentence = \"NLP techniques are used in virtual assistants like Alexa and Siri.\"\n",
    "\n",
    "preprocess(sentence)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23340592",
   "metadata": {},
   "source": [
    "short answer questions:\n",
    "\n",
    "1. What is the difference between stemming and lemmatization? Provide examples with the word “running.”\n",
    "\n",
    "- Stemming reduces words to their root words by removing prefixes or suffixes. It doesn’t consider the context or actual dictionary word.\n",
    "running becomes run but porter stemmer might return run or even runn\n",
    "\n",
    "- Lemmatization reduces words to their lemma which is the dictionary base form of the words using vocabulary and morphological analysis. It considers the part of speech.\n",
    "running is seen as averb and changed to run\n",
    "\n",
    "- One difference between Lemmatization and Stemming is that Lemmatization is more accurate but slower than stemming.\n",
    "\n",
    "2. Why might removing stop words be useful in some NLP tasks, and when might it actually be harmful?\n",
    "- Removing stop words might be useful when performing tasks like text summarization where we focus more on the core content of the text.\n",
    "- Removing stop words might be harmful when performing sentiment analysis tasks. If we remove not from 'not good' then the meaning is lost and results in misclassification. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
